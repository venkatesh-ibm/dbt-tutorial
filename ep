import boto3
import datetime
import time

REGION = "eu-west-1"
DAYS_TO_CHECK = 45

ec2 = boto3.client("ec2", region_name=REGION)
cw = boto3.client("cloudwatch", region_name=REGION)
logs = boto3.client("logs", region_name=REGION)

def bytes_to_human_readable(num_bytes):
    if num_bytes is None:
        return "N/A"
    if num_bytes < 1024:
        return f"{num_bytes} B"
    elif num_bytes < 1024**2:
        return f"{num_bytes/1024:.2f} KB"
    elif num_bytes < 1024**3:
        return f"{num_bytes/1024**2:.2f} MB"
    else:
        return f"{num_bytes/1024**3:.2f} GB"

def get_vpc_names():
    vpc_map = {}
    vpcs = ec2.describe_vpcs()["Vpcs"]
    for vpc in vpcs:
        name = next((t["Value"] for t in vpc.get("Tags", []) if t["Key"] == "Name"), "")
        vpc_map[vpc["VpcId"]] = name
    return vpc_map

def get_flow_log_map():
    """Return dict of VPC IDs that have flow logs enabled."""
    fl_map = {}
    vpcs = ec2.describe_vpcs()["Vpcs"]
    for vpc in vpcs:
        fl_map[vpc["VpcId"]] = False  # default
    flow_logs = ec2.describe_flow_logs()["FlowLogs"]
    for fl in flow_logs:
        if fl["ResourceType"] == "VPC":
            fl_map[fl["ResourceId"]] = True
    return fl_map

def get_cloudwatch_bytes(endpoint_id):
    end_time = datetime.datetime.utcnow()
    start_time = end_time - datetime.timedelta(days=DAYS_TO_CHECK)
    try:
        resp = cw.get_metric_statistics(
            Namespace="AWS/PrivateLinkEndpoints",
            MetricName="BytesProcessed",
            Dimensions=[
                {"Name": "VpcEndpointId", "Value": endpoint_id}
            ],
            StartTime=start_time,
            EndTime=end_time,
            Period=86400,
            Statistics=["Sum"]
        )
        if not resp["Datapoints"]:
            return None
        return sum(dp["Sum"] for dp in resp["Datapoints"])
    except Exception as e:
        print(f"Error fetching CW metrics for {endpoint_id}: {e}")
        return None

def get_flow_log_bytes(eni_ids):
    """Query CloudWatch Logs Insights for total bytes from ENIs."""
    if not eni_ids:
        return None
    start_query = logs.start_query(
        logGroupName="diagnosticflowlogs",
        startTime=int((datetime.datetime.utcnow() - datetime.timedelta(days=DAYS_TO_CHECK)).timestamp()),
        endTime=int(datetime.datetime.utcnow().timestamp()),
        queryString=f"""
            fields interfaceId, bytes
            | filter interfaceId in {eni_ids}
            | stats sum(bytes) as totalBytes
        """
    )
    query_id = start_query["queryId"]

    while True:
        resp = logs.get_query_results(queryId=query_id)
        if resp["status"] in ["Complete", "Failed", "Cancelled"]:
            break
        time.sleep(2)

    if resp["status"] != "Complete" or not resp["results"]:
        return None

    try:
        return int(resp["results"][0][0]["value"])
    except (IndexError, ValueError, KeyError):
        return None

def get_attachment_details(endpoint):
    details = []
    if endpoint.get("NetworkInterfaceIds"):
        details.extend([f"ENI:{eni}" for eni in endpoint["NetworkInterfaceIds"]])
    if endpoint.get("RouteTableIds"):
        details.extend([f"RTB:{rtb}" for rtb in endpoint["RouteTableIds"]])
    return ", ".join(details) if details else "No attachments"

def lambda_handler(event=None, context=None):
    vpc_names = get_vpc_names()
    flow_log_map = get_flow_log_map()

    endpoints = ec2.describe_vpc_endpoints()["VpcEndpoints"]

    table = []
    for ep in endpoints:
        vpc_id = ep["VpcId"]
        vpc_name = vpc_names.get(vpc_id, "")
        service_name = ep["ServiceName"]
        endpoint_id = ep["VpcEndpointId"]

        # Step 1: CloudWatch metric
        bytes_processed = get_cloudwatch_bytes(endpoint_id)

        # Step 2: Fallback to flow logs if needed
        if bytes_processed is None:
            if flow_log_map.get(vpc_id):
                # collect ENIs for this endpoint
                eni_ids = ep.get("NetworkInterfaceIds", [])
                bytes_processed = get_flow_log_bytes(eni_ids)
                if bytes_processed is None:
                    human_readable = "0 Bytes (from flow logs)"
                    usage_status = "Likely Unused"
                else:
                    human_readable = bytes_to_human_readable(bytes_processed)
                    usage_status = "Active" if bytes_processed > 0 else "Likely Unused"
            else:
                human_readable = "N/A (Flow logs not enabled)"
                usage_status = "Unknown (Flow logs disabled)"
        else:
            human_readable = bytes_to_human_readable(bytes_processed)
            usage_status = "Active" if bytes_processed > 0 else "Likely Unused"

        attachments = get_attachment_details(ep)

        table.append([
            vpc_id, vpc_name, endpoint_id, service_name,
            human_readable, attachments, usage_status
        ])

    # Print header
    header = ["VPC ID", "VPC Name", "Endpoint ID", "Service Name",
              "Bytes Processed", "Attachment Details", "Usage Status"]
    print("\t".join(header))
    for row in table:
        print("\t".join(str(cell) for cell in row))

if __name__ == "__main__":
    lambda_handler()
